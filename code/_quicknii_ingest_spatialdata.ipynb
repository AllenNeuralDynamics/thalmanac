{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spatialdata as sd\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "\n",
    "from thalamus_merfish_analysis import abc_load as abc\n",
    "\n",
    "import ccf_registration as ccf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import spatialdata_plot\n",
    "get_ipython().run_line_magic('matplotlib', 'inline') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load and apply transforms\n",
    "\n",
    "Simplest method for script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ccf_transforms import *\n",
    "\n",
    "coords = ['x_section', 'y_section', 'z_section']\n",
    "slice_label = 'slice_int'\n",
    "\n",
    "df_full = abc.get_combined_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = abc.label_thalamus_spatial_subset(df_full, flip_y=False, distance_px=25, \n",
    "                                  cleanup_mask=True, drop_end_sections=True,\n",
    "                                  filter_cells=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref_subset = abc.get_thalamus_reference_ids()\n",
    "# df = ccf.subset_to_ref_bounds(df_full, coords, ref_subset)\n",
    "# minmax = df[coords].agg(['min','max'])\n",
    "# minmax.to_csv(\"resources/brain3_thalamus_coordinate_bounds.csv\")\n",
    "# minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = pd.read_csv(\"/code/resources/brain3_thalamus_coordinate_bounds.csv\", index_col=0)\n",
    "min_xy, max_xy = minmax.loc['min'].values, minmax.loc['max'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_full\n",
    "# df = df.loc[lambda df: \n",
    "#     (df[coords] <= max_xy).all(axis=1) &\n",
    "#     (df[coords] >= min_xy).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[slice_label] = df['z_section'].apply(lambda x: int(x*10))\n",
    "transforms_by_section = ccf.read_quicknii_file(\"resources/adjusted_10-10_final.json\", scale=25)\n",
    "norm_transform = get_normalizing_transform(\n",
    "                                           min_xy=min_xy, \n",
    "                                           max_xy=max_xy, \n",
    "                                           flip_y=True)\n",
    "\n",
    "# load to spatialdata\n",
    "cells_by_section = parse_cells_by_section(df, transforms_by_section, norm_transform, coords, slice_label=slice_label)\n",
    "sdata = sd.SpatialData.from_elements_dict(cells_by_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform\n",
    "transformed_points = pd.concat((\n",
    "    df.compute() for df in \n",
    "    sdata.transform_to_coordinate_system('ccf').points.values()\n",
    "    ))\n",
    "\n",
    "# update dataframe\n",
    "suffix = \"_realigned\"\n",
    "df = df.join(transformed_points[list('xyz')].rename(columns=lambda x: f\"{x}_ccf{suffix}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "obs = df.query(\"slice_int==80\")\n",
    "sns.scatterplot(obs, x='z_ccf_realigned', y='y_ccf_realigned', hue='class', legend=None, s=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "obs = df.query(\"slice_int==80\")\n",
    "sns.scatterplot(obs, x='x_ccf_realigned', y='y_ccf_realigned', hue='class', legend=None, s=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add parcellation index\n",
    "imdata = abc.get_ccf_labels_image(resampled=False)\n",
    "new_coords = [f\"{x}_ccf{suffix}\" for x in 'xyz']\n",
    "df['parcellation_index'+suffix] = imdata[ccf.image_index_from_coords(df[new_coords])]\n",
    "\n",
    "# add parcellation metadata\n",
    "ccf_df = pd.read_csv(abc.ABC_ROOT/f\"metadata/Allen-CCF-2020/20230630/parcellation_to_parcellation_term_membership.csv\")\n",
    "ccf_df = ccf_df.pivot(index='parcellation_index', columns='parcellation_term_set_name', values='parcellation_term_acronym').astype('category')\n",
    "df = df.join(ccf_df[['division','structure','substructure']].rename(columns=lambda x: f\"parcellation_{x}{suffix}\"),\n",
    "             on='parcellation_index'+suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"/data/abc_realigned_metadata_thalamus-boundingbox.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = df.query(\"slice_int==80\")\n",
    "sns.scatterplot(obs, x='z_ccf_realigned', y='y_ccf_realigned', hue='parcellation_substructure_realigned', legend=None, s=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccf_transforms as ccft\n",
    "from importlib import reload\n",
    "reload(ccft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imdata = abc.get_ccf_labels_image()\n",
    "img_transform = sd.transformations.Scale(10e-3*np.ones(3), 'xyz')\n",
    "labels = sd.models.Labels3DModel.parse(imdata, dims='xyz', transformations={'ccf': img_transform})\n",
    "# regions = [f\"{section}_ccf\" for section in cells_by_section.keys()]\n",
    "# ccf_annotation = load_ccf_metadata_table(regions)\n",
    "sdata.add_labels('ccf_regions', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrid = 1100\n",
    "nz = 76\n",
    "\n",
    "z_res = 2\n",
    "img_stack = np.zeros((ngrid, ngrid, nz))\n",
    "for section in sdata.points.keys():\n",
    "    i = int(np.rint(int(section)/z_res))\n",
    "    target = sdata[section]\n",
    "    source = sdata['ccf_regions']\n",
    "    scale = 10e-3\n",
    "    target_img, target_grid_transform = ccft.map_image_to_slice(sdata, imdata, source, target, scale=scale, ngrid=ngrid, centered=False)\n",
    "    img_stack[:,:,i] = target_img.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_stack[:,:,int(np.rint(int(80)/z_res))].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e793862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel\n",
    "nifti_img = nibabel.Nifti1Image(img_stack, affine=np.eye(4))\n",
    "\n",
    "# Save the NIfTI1Image object as .nii file\n",
    "nibabel.save(nifti_img, '/data/labels.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load everything in spatialdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = abc.get_combined_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = abc.label_thalamus_spatial_subset(df_full, filter=True)\n",
    "coords = ['x_section', 'y_section', 'z_section']\n",
    "ref_subset = abc.get_thalamus_reference_ids()\n",
    "df = ccf.subset_to_ref_bounds(df_full, coords, ref_subset)\n",
    "\n",
    "slice_label = 'slice_int'\n",
    "df[slice_label] = df['z_section'].apply(lambda x: int(x*10))\n",
    "\n",
    "# helps plotting etc\n",
    "df = df.assign(**df.select_dtypes(include=[\"category\"]).apply(lambda x: x.cat.remove_unused_categories()).to_dict(orient='series'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_ref = df_full.loc[ref_subset.intersection(df_full.index)]\n",
    "xy = df[coords[:2]]\n",
    "df_min = xy.min()\n",
    "df_max = xy.max()\n",
    "norm_transform = sd.transformations.Sequence([\n",
    "    sd.transformations.Translation(np.array([-1*df_min[0], -1*df_max[1]]), 'xy'),\n",
    "    sd.transformations.Scale(1/(df_max-df_min) * np.array([1, -1]), 'xy')\n",
    "    # above is compensating for inverted y in quicknii template, should be:\n",
    "    # sd.transformations.Translation(-1*df_min, 'xy'),\n",
    "    # sd.transformations.Scale(1/(df_max-df_min), 'xy')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create separate coordinate systems for each section\n",
    "transform_dict = ccf.read_quicknii_file(\"resources/adjusted_10-10_final.json\", scale=25)\n",
    "cells_by_section = dict()\n",
    "for name, df_section in df.groupby(slice_label, observed=True):\n",
    "    ccf_transform = sd.transformations.Affine(transform_dict[name].T, 'xyz', 'xyz')\n",
    "    # cells_by_section[name] = sd.models.ShapesModel.parse(\n",
    "    #     df_section[coords].values, geometry=0, radius=10e-6, \n",
    "    cells_by_section[str(name)] = sd.models.PointsModel.parse(\n",
    "#! converting to dask here is essential to preserve dtypes\n",
    "        dd.from_pandas(df_section, npartitions=1), coordinates=dict(zip('xyz', coords)),\n",
    "        transformations={'ccf': sd.transformations.Sequence([norm_transform, ccf_transform]),\n",
    "                         str(name): sd.transformations.Identity()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! what is going on here!>? (categoricals lost, maybe others)\n",
    "# test = sd.models.PointsModel.parse(df.head(), coordinates=dict(zip('xyz', coords)))\n",
    "# test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_transform = sd.transformations.Scale(10e-3*np.ones(3), 'xyz')\n",
    "# transformation entry takes form of [primary coordinate system name]: [transform from intrinsic coords/pixels to that system]\n",
    "\n",
    "imdata = abc.get_ccf_labels_image()\n",
    "labels = sd.models.Labels3DModel.parse(imdata, dims='xyz', transformations={'ccf': img_transform})\n",
    "# del imdata, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ccf region metadata\n",
    "# (not included/updated in 20230830 version)\n",
    "ccf_df = (\n",
    "        pd.read_csv(\n",
    "        abc.ABC_ROOT/f\"metadata/Allen-CCF-2020/20230630/parcellation_to_parcellation_term_membership.csv\",\n",
    "        dtype={'parcellation_term_acronym': 'category'})\n",
    "          .query(\"parcellation_term_set_name=='substructure'\")\n",
    ")\n",
    "\n",
    "instance_key='parcellation_index'\n",
    "region_key='annotated_element'\n",
    "# regions = list(sdata.labels.keys())\n",
    "regions = [f\"{section}_ccf\" for section in cells_by_section.keys()]\n",
    "# need to repeat table for every annotated element\n",
    "obs = pd.concat([ccf_df.assign(**{region_key: x}) for x in regions])\n",
    "ccf_annotation = sd.models.TableModel.parse(ad.AnnData(obs=obs), region=regions, region_key=region_key, instance_key=instance_key)\n",
    "#! won't save?\n",
    "# sdata.table = ccf_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sdata = sd.SpatialData.from_elements_dict(dict(ccf_regions=labels, table=ccf_annotation, **cells_by_section))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create and add transformed image slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_dict = dict(ccf_regions=labels)\n",
    "for section in sdata.points.keys():\n",
    "    target = sdata[section]\n",
    "    source = sdata['ccf_regions']\n",
    "    scale = 10e-3\n",
    "    target_img, target_grid_transform = map_image_to_slice(sdata, imdata, source, target, scale=scale)\n",
    "    section_labels = sd.models.Labels2DModel.parse(target_img, dims='yx', \n",
    "                             transformations={section: target_grid_transform})\n",
    "    sdata.add_labels(f\"{section}_ccf\", section_labels)\n",
    "    # labels_dict[\"{section}_ccf\"] = section_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite=True is broken?\n",
    "# sdata.write(\"/scratch/abc_atlas_realigned.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorcet import glasbey, gray\n",
    "section = '70'\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "ccf_label = 'parcellation_term_acronym'\n",
    "i_set = np.unique(sdata[f\"{section}_ccf\"])\n",
    "ccf_groups = ccf_df.loc[ccf_df[instance_key].isin(i_set), ccf_label].unique()\n",
    "\n",
    "groups = sdata[section]['subclass'].value_counts().loc[lambda x: x>0].index.compute()\n",
    "groups = [x for x in groups if not 'NN' in x]\n",
    "(\n",
    "    sdata\n",
    "    .pl.render_points(size=0.02, color='subclass', groups=groups, palette=glasbey)\n",
    "    .pl.render_labels(palette=gray*4, color=ccf_label, groups=ccf_groups, outline=True)\n",
    "    .pl.show(coordinate_systems=[section], ax=ax, na_in_legend=False)\n",
    ")\n",
    "ax.set_ylim(7.5, 3)\n",
    "ax.set_xlim(2.5, 8.5)\n",
    "ax.get_legend().remove()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image transform single section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = sd.SpatialData.from_elements_dict(dict(ccf_regions=labels, table=ccf_annotation, **cells_by_section))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test single section\n",
    "\n",
    "section = '70'\n",
    "target = sdata[section]\n",
    "source = sdata['ccf_regions']\n",
    "scale = 10e-3\n",
    "target_img, target_grid_transform = map_image_to_slice(source, target, scale=scale)\n",
    "section_labels = sd.models.Labels2DModel.parse(\n",
    "    target_img, dims='yx', \n",
    "    transformations={section: target_grid_transform})\n",
    "sdata.add_labels(f\"{section}_ccf\", section_labels)\n",
    "\n",
    "#! trimmed dimensions are erased when sdata creates SpatialImage\n",
    "# section_labels = section_labels[(section_labels != 0).any(dim='x'),\n",
    "#                (section_labels != 0).any(dim='y')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorcet import glasbey, gray\n",
    "section = '70'\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "ccf_label = 'parcellation_term_acronym'\n",
    "i_set = np.unique(sdata[f\"{section}_ccf\"])\n",
    "ccf_groups = ccf_df.loc[ccf_df[instance_key].isin(i_set), ccf_label].unique()\n",
    "\n",
    "groups = sdata[section]['subclass'].value_counts().loc[lambda x: x>0].index.compute()\n",
    "groups = [x for x in groups if not 'NN' in x]\n",
    "(\n",
    "    sdata\n",
    "    .pl.render_points(size=0.02, color='subclass', groups=groups, palette=glasbey)\n",
    "    .pl.render_labels(palette=gray*4, color=ccf_label, groups=ccf_groups, outline=True)\n",
    "    .pl.show(coordinate_systems=[section], ax=ax, na_in_legend=False)\n",
    ")\n",
    "ax.set_ylim(7.5, 3)\n",
    "ax.set_xlim(2.5, 8.5)\n",
    "ax.get_legend().remove()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### details of image transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "coords = np.arange(-ngrid/2, ngrid/2)\n",
    "# use xarray broadcasting to create a centered coord grid\n",
    "# (dims are named 'xx' etc as matching variable names not allowed)\n",
    "# (yx order for image layout)\n",
    "axes = [xr.DataArray(data=scale*coords + target_center[n], coords={i+i: coords}, dims=i+i, name=i) \n",
    "        for n, i in enumerate('xy')]\n",
    "grid = xr.merge(axes[::-1])\n",
    "grid['z'] = target_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_points = grid.to_array().to_numpy().reshape(3, -1)\n",
    "source_points = ccf.apply_affine_left(mat, target_points)\n",
    "\n",
    "target_img = scipy.ndimage.map_coordinates(imdata, source_points[::-1, :] - 0.5, prefilter=False, order=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = target_img\n",
    "plt.imshow(img, origin='lower')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alternative approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# option using sdata PointsModel\n",
    "# if added to sdata could specify coord system and infer transform, keeping original coords too\n",
    "# (maybe nicer for creating SpatialImage coords)\n",
    "source_points = sd.transform(sd.models.PointsModel.parse(target_points.T), transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no way to selectively index to fill past edges?! \n",
    "# (ie where() with dask delayed evaluation?)\n",
    "# round_to_centers = lambda x: (x - 0.5).round().astype(int)\n",
    "# ind = round_to_centers(source_points).compute()\n",
    "# ind[ind<0] = np.nan\n",
    "# for i in 'xyz':\n",
    "#     ind[i] = ind[i].where(ind[i] < len(source[i]))\n",
    "    \n",
    "# can't index with nan\n",
    "# x, y, z = (xr.DataArray(ind[i], dims=['i']) for i in 'xyz')\n",
    "# target_img = source[z, y, x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounding, reindexing, and array indexing mimics map_coordinates (slowly)\n",
    "# rounding is necessary so reindexing (on unique) is smaller\n",
    "round_to_centers = lambda x: (x - 0.5).round() + 0.5\n",
    "ind = round_to_centers(source_points)\n",
    "# dask option needed to not complain here (set T or F)\n",
    "import dask.config\n",
    "with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "# reindex will fill nan for outside points\n",
    "# (could also do by inequality and index without rounding)\n",
    "    subset = source.reindex({x: ind[x].unique() for x in ind.columns}).compute()\n",
    "# defining single shared dim prevents broadcasting\n",
    "# whereas this broadcasts to a cube array\n",
    "# subset.sel(z=ind['z'], y=ind['y'], x=ind['x'])\n",
    "x, y, z = (xr.DataArray(ind[i], dims=['i']) for i in 'xyz')\n",
    "target_img = subset.loc[z, y, x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = target_img.values.reshape(ngrid, ngrid).T\n",
    "plt.imshow(img, origin='lower')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.array import from_array\n",
    "from spatial_image import SpatialImage\n",
    "\n",
    "img_arr = xr.DataArray(from_array(img), \n",
    "                       coords={i: grid.data_vars[i].values for i in 'xyz'}, dims=['y','x'])\n",
    "\n",
    "\n",
    "img_spa = SpatialImage(img_arr, attrs=dict(transform={section: sd.transformations.Identity()}))\n",
    "img_spa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_dict = {i: xr.DataArray(target[i], dims=['i']) for i in 'xy'}\n",
    "cell_regions = img_spa.sel(**coords_dict, method='nearest', tolerance=0.5).values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coords = ['x_ccf','y_ccf','z_ccf']\n",
    "# cells = target.dropna(subset=coords)\n",
    "# coords_dict = {i[0]: xr.DataArray(cells[i].dropna()/0.01, dims=['i']) for i in coords}\n",
    "cells = sd.transform(target, transform)\n",
    "coords_dict = {i: xr.DataArray(cells[i], dims=['i']) for i in 'xyz'}\n",
    "cell_regions2 = source.sel(**coords_dict, method='nearest', tolerance=0.5).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cell_regions2 == cell_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelsModel replaces existing coordinates with pixel indices!!\n",
    "# sd.models.Labels2DModel.parse(data=img_arr, )\n",
    "\n",
    "# same happens if added directly as SpatialImage\n",
    "# name = f\"ccf_{section}\"\n",
    "# sdata.add_labels(name, img_spa)\n",
    "# sdata[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fails beyond tolerance rather than fill nan\n",
    "# coords_dict = {i: xr.DataArray(transformed_coords[i], dims=['i']) for i in 'xyz'}\n",
    "# transformed_img = source.sel(**coords_dict, method='nearest', tolerance=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
